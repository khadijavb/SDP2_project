import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import docx
doc1 = docx.Document("C:/Users/ACER PREDATOR/Desktop/d1.docx")
fullText1 = []
for para in doc1.paragraphs:
  fullText1.append(para.text)

doc2 = docx.Document("C:/Users/ACER PREDATOR/Desktop/d2.docx")
fullText2 = []
for para in doc2.paragraphs:
  fullText2.append(para.text)

X_list= []
for p in fullText1:
    X_list.append(word_tokenize(p))
    
Y_list= [] 
for p in fullText2:
    Y_list.append(word_tokenize(p))


sw = stopwords.words('english')
l1 =[];l2 =[]

X_set = {w for w in X_list if not w in sw}
Y_set = {w for w in Y_list if not w in sw}

rvector = X_set.union(Y_set)
for w in rvector:
	if w in X_set: l1.append(1) # create a vector
	else: l1.append(0)
	if w in Y_set: l2.append(1)
	else: l2.append(0)
c = 0

# cosine formula
for i in range(len(rvector)):
		c+= l1[i]*l2[i]
cosine = c / float((sum(l1)*sum(l2))**0.5)
print("similarity: ", cosine)
