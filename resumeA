import docx2txt
import spacy
import re
import docx
import os
import numpy as np
from scipy.spatial.distance import canberra
nlp = spacy.load("en_core_web_lg")

phone_pattern = re.compile(r"\b\d{3}\D{0,3}\d{3}\D{0,3}\d{4}\b")
email_pattern = re.compile(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,4}")
experience_pattern = re.compile(r'(\d+)\+?\s*(?:year|yr)s?\s+of\s+experience\s+in\s+(.*)', re.IGNORECASE)
education_pattern = re.compile(r"([A-Z][a-z]+(?:\s[A-Z][a-z]+))[\n\s]+([A-Z][a-z]+(?:\s[A-Z][a-z]+))(?:[\n\s]+[A-Z]{2}[\n\s]+)")
language_pattern = re.compile(r'\b(?:English|French|German|Spanish|Italian|Portuguese|Russian|Chinese|Japanese|vietnamese|Korean|Hindi|Ukrainian|Bengali)\b', re.IGNORECASE)
job_title_pattern = r"\b(\w+\s)*(manager|director|engineer|analyst|specialist|consultant|coordinator)\b"

doc1 = docx.Document("C:/Users/User/Desktop/req.docx")
reqs_list=[]
for para in doc1.paragraphs:
    reqs = para.text.split(",")
    reqs_list.extend([req.strip().replace('\xa0', ' ').lower() for req in reqs if req.strip()])


skills_list = ['java', 'c++', 'javascript','php','ruby', 'html', 'css', 'react','sql', 'node', 'aws','web development','machine learning','artificial intelligence','composing','first aid',' use and disposal of chemicals', 'business consulting', 'teaching','math','project management', 'public speaking', 'accounting', 'python', 'communication', 'html5', 'MySQL', 'c#', 'singing', 'dancing', 'idol', 'arts']

def extract_sec_info(resume_text, skills_list):
    doc = nlp(resume_text)
    name = None
    for ent in doc.ents:
        if ent.label_ == "PERSON":
            name = ent.text
            break

    phone_number = None
    for match in re.findall(phone_pattern, resume_text):
        phone_number = match
        break

    email = None
    for match in re.findall(email_pattern, resume_text):
        email = match
        break
    
    return {
        "name": name,
        "phone_number": phone_number,
        "email": email,
        } 

def extract_info(resume_text, skills_list):
    doc = nlp(resume_text)
    skills = []
    for skill in skills_list:
        if skill.lower() in resume_text.lower():
            skills.append(skill.lower())
    skills = list(set(skills))
   
    experience = []
    for match in experience_pattern.finditer(resume_text):
        years_of_experience = match.group(1)
        field = match.group(2)
        experience_str = f"{years_of_experience} years of experience in {field}"
        experience.append(experience_str.replace('\xa0', '').lower())


    job_titles = re.findall(job_title_pattern, resume_text, re.IGNORECASE)
    for title in job_titles:
        experience.append(''.join(filter(None, title)).lower())

    education = []
    for match in re.findall(education_pattern, resume_text):
        degree = match[0].lower()
        institution = match[1].lower()
        education.append(degree + ' ' + institution)

    if not education:
        lines = resume_text.split('\n')
        for line in lines:
            if 'degree' in line.lower() or 'bachelor' in line.lower() or 'master' in line.lower():
                education.append(line.strip().lower())
    
    languages = []       
    for match in re.findall(language_pattern, resume_text):
        languages.append(match.lower())
    
    my_list=[]
    my_list.extend(skills)
    my_list.extend(experience)
    my_list.extend(education)
    my_list.extend(languages)
    
    return my_list


folder_path = "C:/Users/User/Desktop/resumes"

def hamming_distance(list1, list2):
    distance = 0
    for i in range(len(list1)):
        if list1[i] != list2[i]:
            distance += 1
    return distance

for filename in os.listdir(folder_path):
    file_path = os.path.join(folder_path, filename)
    
    if filename.endswith(".docx"):
        resume_text = docx2txt.process(file_path)
        info = extract_info(resume_text, skills_list)
        sec_info=extract_sec_info(resume_text, skills_list)
       
       

    if len(info) > len(reqs_list):
        max_len = len(info)
        reqs_list += ' ' * (max_len - len(reqs_list))
    else:
        max_len = len(reqs_list)
        info += ' ' * (max_len - len(info))

    distance = hamming_distance(info, reqs_list)
    print("Resume:", filename)
    print("similarity:", "%.1f" % (distance))
    print()